from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel
from openai import AzureOpenAI
import os
from dotenv import load_dotenv
from app.core.config import settings
from pymongo import MongoClient
from typing import Optional, List, Dict, Any
import json
import logging
from datetime import datetime
import re # <-- Importar para detecci칩n de preguntas simples
# --- NUEVO: Importar SQLAlchemy y modelo Center ---
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.models.models import Center
import base64
from dateutil.relativedelta import relativedelta
from dateutil import parser as date_parser
import calendar

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

# Cargar variables de entorno si no est치n ya cargadas
load_dotenv()

# Configurar el cliente de Azure OpenAI
client = AzureOpenAI(
    api_version=settings.azure_openai_api_version,
    azure_endpoint=settings.azure_openai_endpoint,
    api_key=settings.azure_openai_api_key,
    http_client=None
)

# Cliente de OpenAI para TTS (usa las credenciales TTS independientes)
tts_client = AzureOpenAI(
    api_version=settings.azure_openai_tts_api_version,
    azure_endpoint=settings.azure_openai_tts_endpoint,
    api_key=settings.azure_openai_tts_api_key,
    http_client=None
)

# Configurar la conexi칩n a MongoDB
MONGO_URI = os.getenv("MONGO_URI", "mongodb://10.20.7.102:27017/")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME", "wisensor_db")
MONGO_COLLECTION_NAME = os.getenv("MONGO_COLLECTION_NAME", "analyzed_reports")
MONGO_CHAT_HISTORY_COLLECTION_NAME = os.getenv("MONGO_CHAT_HISTORY_COLLECTION_NAME", "chat_history")
MONGO_CENTERS_COLLECTION_NAME = os.getenv("MONGO_CENTERS_COLLECTION_NAME", "centers")
MONGO_ALIMENTACION_COLLECTION_NAME = os.getenv("MONGO_ALIMENTACION_COLLECTION_NAME", "alimentacion")
MONGO_CLIMA_COLLECTION_NAME = os.getenv("MONGO_CLIMA_COLLECTION_NAME", "clima")


try:
    mongo_client = MongoClient(MONGO_URI)
    mongo_db = mongo_client[MONGO_DB_NAME]
    analyzed_reports_collection = mongo_db[MONGO_COLLECTION_NAME]
    chat_history_collection = mongo_db[MONGO_CHAT_HISTORY_COLLECTION_NAME]
    centers_collection = mongo_db[MONGO_CENTERS_COLLECTION_NAME]
    alimentacion_collection = mongo_db[MONGO_ALIMENTACION_COLLECTION_NAME]
    clima_collection = mongo_db[MONGO_CLIMA_COLLECTION_NAME]
    logger.info(f"Conexi칩n a MongoDB exitosa. Base de datos: {MONGO_DB_NAME}, Colecci칩n de informes: {MONGO_COLLECTION_NAME}, Colecci칩n de historial de chat: {MONGO_CHAT_HISTORY_COLLECTION_NAME}, Colecci칩n de centros: {MONGO_CENTERS_COLLECTION_NAME}, Colecci칩n de alimentaci칩n: {MONGO_ALIMENTACION_COLLECTION_NAME}")
except Exception as e:
    logger.error(f"Error al conectar con MongoDB: {e}")

class QuestionRequest(BaseModel):
    user_question: str
    center_id: int
    informe_filename: Optional[str] = None # Opcional si la pregunta es sobre un informe espec칤fico

# --- ELIMINADO: Detecci칩n manual de preguntas simples ---
# Ahora la IA determina autom치ticamente qu칠 tipo de pregunta es

def needs_alimentacion_context(question: str) -> bool:
    # Palabras clave para decidir si incluir datos de alimentaci칩n
    keywords = ["alimentacion", "alimento", "pez", "peces", "jaula", "biomasa", "MOT", "dieta", "feed", "silo", "doser", "peso"]
    q = question.lower()
    return any(k in q for k in keywords)
def needs_clima_context(question: str) -> bool:
    keywords = ["clima", "temperatura", "ox칤geno", "presi칩n", "humedad", "radiaci칩n", "viento", "atm칩sfera", "meteorolog칤a", "climatolog칤a"]
    q = question.lower()
    return any(k in q for k in keywords)


def is_list_alimentacion_centros_question(question: str) -> bool:
    # Detectar preguntas como '쯣ara qu칠 centros hay datos de alimentaci칩n?' o similares
    patterns = [
        r"para que centros hay datos de alimentaci[칩o]n",
        r"centros.*alimentaci[칩o]n",
        r"alimentaci[칩o]n.*centros",
        r"centros.*tienen.*alimentaci[칩o]n",
        r"alimentaci[칩o]n.*disponible.*centros"
    ]
    q = question.lower()
    return any(re.search(p, q) for p in patterns)

def detect_period_from_question(question: str):
    """
    Detecta un periodo temporal en la pregunta y retorna un filtro de fechas (start, end) o None.
    Soporta: verano, invierno, primavera, oto침o, a침o, mes, semana, hoy, ayer, etc.
    """
    import re
    from datetime import datetime, timedelta
    q = question.lower()
    now = datetime.utcnow()
    year = now.year
    # Mapas de estaciones (hemisferio sur)
    seasons = {
        "verano": (datetime(year, 12, 21), datetime(year+1, 3, 20)),
        "invierno": (datetime(year, 6, 21), datetime(year, 9, 22)),
        "primavera": (datetime(year, 9, 23), datetime(year, 12, 20)),
        "oto침o": (datetime(year, 3, 21), datetime(year, 6, 20)),
    }
    for s, (start, end) in seasons.items():
        if s in q:
            # Si estamos fuera de la estaci칩n, ajustar a침o
            if start > end:
                if now.month < 6:
                    start = start.replace(year=year-1)
                else:
                    end = end.replace(year=year+1)
            return start, end
    # A침o espec칤fico
    m = re.search(r"(20\d{2})", q)
    if m:
        y = int(m.group(1))
        return datetime(y, 1, 1), datetime(y, 12, 31, 23, 59, 59)
    # Mes espec칤fico
    meses = ["enero", "febrero", "marzo", "abril", "mayo", "junio", "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"]
    for i, mes in enumerate(meses, 1):
        if mes in q:
            return datetime(year, i, 1), datetime(year, i, calendar.monthrange(year, i)[1], 23, 59, 59)
    # 칔ltima semana
    if "ultima semana" in q or "칰ltima semana" in q or "la semana pasada" in q:
        return now - timedelta(days=7), now
    # Hoy
    if "hoy" in q:
        return now.replace(hour=0, minute=0, second=0, microsecond=0), now
    # Ayer
    if "ayer" in q:
        ayer = now - timedelta(days=1)
        return ayer.replace(hour=0, minute=0, second=0, microsecond=0), ayer.replace(hour=23, minute=59, second=59, microsecond=999999)
    return None

def aggregate_alimentacion(alimentacion_collection, center_name, period=None, limit=100):
    """
    B칰squeda flexible: busca todos los registros donde 'Name' contenga el nombre del centro (case-insensitive).
    Si period es (start, end), filtra por ese rango. Si no, usa los 칰ltimos N registros.
    Devuelve agregados: promedio, suma, min, max, count para cada campo num칠rico relevante.
    Adem치s, incluye una muestra de hasta 5 registros representativos (los m치s recientes).
    """
    if not center_name:
        return {"resumen": "No se especific칩 centro para la b칰squeda de alimentaci칩n."}
    regex = re.compile(re.escape(center_name), re.IGNORECASE)
    match = {"Name": {"$regex": regex}}
    if period:
        start, end = period
        match["FechaHora"] = {"$gte": start, "$lte": end}
        pipeline = [
            {"$match": match},
            {"$sort": {"FechaHora": -1}},
            {"$limit": 10000}
        ]
        docs = list(alimentacion_collection.aggregate(pipeline))
    else:
        docs = list(alimentacion_collection.find(match).sort("FechaHora", -1).limit(limit))
    for doc in docs:
        doc.pop("_id", None)
    if not docs:
        return {"resumen": "No hay datos de alimentaci칩n para el periodo/centro consultado."}
    numeric_fields = [k for k, v in docs[0].items() if isinstance(v, (int, float))]
    resumen = {}
    for field in numeric_fields:
        values = [d[field] for d in docs if isinstance(d.get(field), (int, float))]
        if not values:
            continue
        resumen[field] = {
            "promedio": sum(values)/len(values),
            "suma": sum(values),
            "min": min(values),
            "max": max(values),
            "count": len(values)
        }
    resumen["total_registros"] = len(docs)
    resumen["ejemplo_registros"] = docs[:5]
    return resumen
def aggregate_clima(clima_collection, codigo_centro, period=None, limit=100):
    """
    Agrega datos clim치ticos para un centro espec칤fico por c칩digo y periodo (si se indica).
    Devuelve promedios, min, max, count y una muestra representativa.
    """
    if not codigo_centro:
        return {"resumen": "No se especific칩 c칩digo de centro para la b칰squeda de clima."}

    match = {"codigo_centro": codigo_centro}

    if period:
        start, end = period
        match["fecha"] = {"$gte": start, "$lte": end}
        docs = list(clima_collection.find(match).sort("fecha", -1).limit(10000))
    else:
        docs = list(clima_collection.find(match).sort("fecha", -1).limit(limit))

    for doc in docs:
        doc.pop("_id", None)
        doc["fecha"] = str(doc["fecha"])

    if not docs:
        return {"resumen": "No hay datos de clima disponibles para el periodo/centro."}

    datos_climaticos = [d["datos"] for d in docs if "datos" in d]
    numeric_fields = [k for k, v in datos_climaticos[0].items() if isinstance(v, (int, float))]

    resumen = {}
    for field in numeric_fields:
        values = [d[field] for d in datos_climaticos if isinstance(d.get(field), (int, float))]
        if not values:
            continue
        resumen[field] = {
            "promedio": sum(values)/len(values),
            "min": min(values),
            "max": max(values),
            "count": len(values)
        }

    resumen["total_registros"] = len(datos_climaticos)
    resumen["ejemplo_registros"] = datos_climaticos[:5]
    return resumen


# --- DEFINICI칍N DE HERRAMIENTA PARA EL LLM (Function Calling) ---
# Esto debe ir en la parte superior de tu archivo, fuera de cualquier funci칩n.
GET_FULL_ANALYSIS_TOOL = {
    "type": "function",
    "function": {
        "name": "get_full_report_analysis",
        "description": "Obtiene el contenido t칠cnico detallado (full_analysis) de uno o varios informes ambientales para an치lisis o comparaci칩n. 칔sala cuando el usuario pregunte por datos t칠cnicos espec칤ficos (ej. pH, redox, materia org치nica, valores de contaminantes), conclusiones o un an치lisis profundo de un informe. **Para valores de par치metros como pH o Redox, prioriza los datos generales o promedios del informe para gr치ficos, a menos que se soliciten 'por estaci칩n' o 'por punto de muestreo'.** Tambi칠n sirve si el usuario solicita una comparaci칩n o tendencia de m칰ltiples informes (ej. 'los 칰ltimos 2 informes').",
        "parameters": {
            "type": "object",
            "properties": {
                "center_id": {
                    "type": "integer",
                    "description": "El ID num칠rico del centro al que pertenece el informe. Se puede inferir del contexto de la sesi칩n."
                },
                "informe_filename": {
                    "type": "string",
                    "description": "El nombre exacto o una referencia parcial del archivo del informe ambiental (ej. 'Anexo 1 Informe Laboratorio Pirquen 23 marzo 2023.pdf', 'el informe de marzo', 'el anexo 1'). Si el usuario no proporciona un nombre espec칤fico, la herramienta buscar치 el informe m치s reciente para el centro."
                },
                "num_reports": {
                    "type": "integer",
                    "description": "El N칔MERO DE INFORMES M츼S RECIENTES a recuperar SOLO SI el usuario expl칤citamente solicita una comparaci칩n o menciona 'los 칰ltimos N informes' (ej., 'los 칰ltimos 3'). No asumas un valor si no se menciona un n칰mero espec칤fico. Por defecto es 1 si no se especifica un n칰mero."
                }
            },
            "required": ["center_id"]
        }
    }
}

# --- MODIFICADO: Agregar db: Session = Depends(get_db) ---
@router.post("/analyze-question/")
async def analyze_question(request: QuestionRequest, db: Session = Depends(get_db)):
    try:
        user_question_lower = request.user_question.lower()
        logger.info(f"Pregunta recibida: '{user_question_lower}' para centro ID: {request.center_id}")

        # --- Preparar contexto b치sico e inicial (se mantiene igual) ---
        center = db.query(Center).filter(Center.id == request.center_id).first()
        center_name = center.name if center else "desconocido"
        
        all_centers = db.query(Center).all()
        all_centers_data = [
            {"id": c.id, "nombre": c.name, "codigo": c.code, "latitud": c.latitude, "longitud": c.longitude}
            for c in all_centers
        ]

        unified_context: Dict[str, Any] = {
            "centro_actual_seleccionado": {"id": request.center_id, "nombre": center_name},
            "todos_los_centros_disponibles": all_centers_data,
        }

        # --- Flujo unificado: Dejar que la IA determine qu칠 tipo de pregunta es y responda apropiadamente ---
        
        # --- NUEVO BLOQUE: FASE 1 - La IA decide si necesita datos pesados (Function Calling) ---
        messages_for_llm_tool_check = [
            {"role": "system", "content": f"""
            Eres un asistente de IA cuya tarea es determinar qu칠 informaci칩n necesita el usuario para responder a su pregunta.
            Basado en la pregunta del usuario y el contexto operativo (informaci칩n sobre centros, informes, datos de alimentaci칩n), decide si necesitas usar alguna de las funciones disponibles para obtener datos espec칤ficos de la base de datos.
            **No respondas a la pregunta directamente en esta fase; solo genera la llamada a la funci칩n si es necesaria.** Si la pregunta no requiere datos espec칤ficos de las herramientas disponibles, no llames a ninguna funci칩n y contin칰a a la siguiente fase sin a침adir informaci칩n pesada.
            El centro de inter칠s actual es {center_name} (ID: {request.center_id}). Si el usuario menciona un nombre de archivo, prioriza ese para la funci칩n get_full_report_analysis.
            """},
            {"role": "user", "content": request.user_question}
        ]

        logger.info("Iniciando primera llamada al LLM para detecci칩n de intenci칩n (Function Calling)...")
        first_llm_response = client.chat.completions.create(
            model=settings.azure_openai_deployment,
            messages=messages_for_llm_tool_check,
            tools=[GET_FULL_ANALYSIS_TOOL],
            tool_choice="auto"
        )

        tool_calls = first_llm_response.choices[0].message.tool_calls
        
        # --- Ejecuci칩n Condicional de la Herramienta (si el LLM la solicit칩) ---
        if tool_calls:
            logger.info(f"LLM solicit칩 {len(tool_calls)} herramienta(s).")
            # *** NOTA: Por ahora, tu c칩digo solo procesa la primera herramienta de la lista.
            # *** Si el LLM realmente solicita 2 herramientas (como en tu log),
            # *** deber칤as iterar sobre `tool_calls` para ejecutar cada una si es necesario.
            # *** Por simplicidad y para resolver el problema actual, seguiremos con `tool_calls[0]`.
            tool_call = tool_calls[0] 
            function_name = tool_call.function.name

            if function_name == "get_full_report_analysis":
                function_args = {}
                try:
                    function_args = json.loads(tool_call.function.arguments)
                except json.JSONDecodeError:
                    logger.error(f"Error decodificando argumentos JSON para {function_name}: {tool_call.function.arguments}")
                    unified_context["error_tool_call"] = f"Error al decodificar argumentos para {function_name}."

                target_center_id = function_args.get("center_id", request.center_id)
                requested_filename = function_args.get("informe_filename") 
                # --- AQU칈 EMPIEZAN LOS CAMBIOS DENTRO DE ESTE BLOQUE `if function_name == ...` ---
                # 1. Obtener el nuevo par치metro 'num_reports' de los argumentos de la funci칩n
                num_reports = function_args.get("num_reports", 1) # Por defecto es 1 si no se especifica

                found_reports_data = [] # Esta lista almacenar치 todos los informes encontrados

                if target_center_id:
                    query_filter = {"center_id": target_center_id}
                    sort_criteria = [("report_date", -1)] 

                    # 2. L칩gica para buscar uno o m칰ltiples informes (REEMPLAZA el bloque 'if requested_filename: ... else: ...' anterior)
                    if requested_filename:
                        logger.info(f"Buscando informe(s) para centro {target_center_id} con referencia: '{requested_filename}'.")
                        regex_pattern = re.compile(re.escape(requested_filename), re.IGNORECASE)
                        query_filter["original_filename"] = {"$regex": regex_pattern}
                        
                        # Usa find() y limit para buscar por nombre de archivo espec칤fico o patr칩n
                        reports_cursor = analyzed_reports_collection.find(
                            query_filter,
                            {"full_analysis": 1, "report_date": 1, "original_filename": 1, "_id": 0} # Proyecta campos adicionales
                        ).sort(sort_criteria).limit(num_reports) 
                        
                        found_reports_data = list(reports_cursor)
                    else:
                        logger.info(f"No se especific칩 nombre de informe. Buscando los 칰ltimos {num_reports} informes para el centro {target_center_id}.")
                        
                        # Usa find() y limit para los N informes m치s recientes para el centro
                        reports_cursor = analyzed_reports_collection.find(
                            query_filter, 
                            {"full_analysis": 1, "report_date": 1, "original_filename": 1, "_id": 0} # Proyecta campos adicionales
                        ).sort(sort_criteria).limit(num_reports) 
                        
                        found_reports_data = list(reports_cursor)

                # 3. C칩mo se agrega el resultado al unified_context (REEMPLAZA el bloque 'if full_analysis_doc: ... else: ...' anterior)
                if found_reports_data:
                    # 춰IMPORTANTE! Cambia la clave a plural y almacena una LISTA de informes
                    unified_context["informes_ambientales_detallados"] = [] 
                    for doc in found_reports_data:
                        if "full_analysis" in doc:
                            unified_context["informes_ambientales_detallados"].append({
                                "filename": doc.get("original_filename"),
                                "report_date": doc.get("report_date"),
                                "analysis": doc["full_analysis"]
                            })
                    logger.info(f"'{len(found_reports_data)}' informe(s) detallado(s) cargado(s) con 칠xito en el contexto unificado.")
                else:
                    logger.warning(f"No se encontr칩 el campo 'full_analysis' para la descripci칩n '{requested_filename}' en centro {target_center_id} o no hay informes que coincidan.")
                    # Aseg칰rate de que este mensaje se alinee con tu nueva forma de b칰squeda m칰ltiple/칰ltimo
                    unified_context["informe_ambiental_detallado"] = f"No disponible el an치lisis detallado para el informe(s) que solicitaste en este centro. Por favor, s칠 m치s espec칤fico o consulta los informes disponibles."

            # Puedes a침adir aqu칤 otros 'elif function_name == "otra_herramienta":' si tienes m치s herramientas
            # Por ahora, solo tenemos 'get_full_report_analysis'

        else:
            # Esta parte se mantiene igual, es para cuando el LLM NO usa ninguna herramienta
            logger.info("LLM no solicit칩 'full_analysis'. Cargando res칰menes de informes disponibles.")
            query_filter_basic = {"center_id": request.center_id}
            if request.informe_filename: # Esto parece ser un remanente, `request.informe_filename` no deber칤a usarse aqu칤
                query_filter_basic["original_filename"] = request.informe_filename
            
            projection_summary = {
                "report_type": 1, 
                "original_filename": 1, 
                "extracted_at": 1,
                "report_date": 1,
                "_id": 0 
            }
            resumed_docs = list(analyzed_reports_collection.find(query_filter_basic, projection_summary).limit(5))
            unified_context["informes_resumidos_disponibles"] = resumed_docs
            logger.info("Contexto de informes resumidos cargado.")

        # --- Tu l칩gica existente para contexto de alimentaci칩n (se mantiene igual) ---
        alimentacion_centros = alimentacion_collection.distinct("Name")
        clima_codigos = clima_collection.distinct("codigo_centro")
        clima_centros = []
        for codigo in clima_codigos:
            centro = db.query(Center).filter(Center.code == str(codigo)).first()
            if centro:
                clima_centros.append({
                    "id": centro.id,
                    "nombre": centro.name,
                    "codigo": centro.code
                })

        period = detect_period_from_question(request.user_question)
        alimentacion_summary = None
        if needs_alimentacion_context(request.user_question):
            alimentacion_summary = aggregate_alimentacion(alimentacion_collection, center_name, period=period, limit=100)
        clima_summary = None
        if needs_clima_context(request.user_question):
            codigo_centro = center.code if center else None
            if codigo_centro:
                try:
                    codigo_centro = int(codigo_centro)
                except:
                    codigo_centro = None
            clima_summary = aggregate_clima(clima_collection, codigo_centro, period=period, limit=100)
        
        # Actualizar el contexto unificado con todos los datos recolectados
        unified_context["centros_con_alimentacion"] = alimentacion_centros
        unified_context["centros_con_clima"] = clima_centros

        if alimentacion_summary is not None:
            unified_context["resumen_alimentacion_centro_actual"] = alimentacion_summary
        if clima_summary is not None:
            unified_context["resumen_clima_centro_actual"] = clima_summary
        # Convertir el contexto unificado a string JSON formateado
        context_str = json.dumps(unified_context, indent=2, default=str)
        
        # Definir el prompt principal con el contexto operativo
        prompt_content = f"""
Eres un asistente de inteligencia artificial especializado en an치lisis ambiental y operacional de centros de cultivo de salmones en Chile. Tu objetivo es interpretar preguntas humanas de forma contextual, identificar la intenci칩n de la solicitud, y entregar una respuesta clara, 칰til y fundamentada basada en los datos disponibles.

**PRIORIDAD: S칠 conciso y utiliza solo la informaci칩n estrictamente necesaria del contexto proporcionado para responder a la pregunta. Evita la verbosidad y la inclusi칩n de detalles no solicitados expl칤citamente. Apunta a la eficiencia en el uso de tokens.**

### 游 CONTEXTO OPERATIVO DISPONIBLE

Tienes acceso a m칰ltiples bases de datos relacionadas a centros de cultivo, cada una con informaci칩n distinta. No todos los centros est치n presentes en todas las bases.

- **`todos_los_centros_disponibles` (MySQL)**: Cat치logo oficial de centros (ID, nombre, c칩digo, latitud, longitud).
- **`centro_actual_seleccionado`**: Informaci칩n del centro que se est치 consultando.

- **INFORMES AMBIENTALES (analyzed_reports)**: Estudios t칠cnicos del fondo marino que pueden incluir materia org치nica, algas en sedimentos, pH, redox, profundidad, etc.
    - **`informes_ambientales_detallados`**: **Si est치 presente**, esta es una **lista de objetos JSON**, donde cada objeto contiene el `filename`, `report_date` y el `analysis` completo de un informe ambiental. **칔sala para responder preguntas detalladas, extraer valores espec칤ficos o realizar comparaciones y tendencias entre m칰ltiples informes.**
    - **`informes_resumidos_disponibles`**: Si **`informes_ambientales_detallados` NO est치 presente** y la pregunta no es espec칤fica, este campo contendr치 metadatos b치sicos (tipo, nombre de archivo, fecha de extracci칩n/informe) de informes ambientales disponibles. 칔salo para preguntas generales como "쯤u칠 informes hay?" o listar informes.
    - **`nombres_de_informes_disponibles_para_inferencia`**: **(Siempre presente si hay informes)** Lista de nombres de archivos recientes para el centro actual, para ayudar en la identificaci칩n.

- **DATOS DE ALIMENTACI칍N (MongoDB)**:
    - **`resumen_alimentacion_centro_actual`**: **Si est치 presente**, contiene estad칤sticas agregadas (promedio, suma, min, max) de datos de alimentaci칩n para el centro y periodo solicitado (ej. biomasa, consumo de alimento, temperatura del agua).
    - **`centros_con_alimentacion`**: Lista los nombres de los centros que tienen datos de alimentaci칩n.
- **DATOS CLIM츼TICOS (MongoDB)**:
    - **`resumen_clima_centro_actual`**: Estad칤sticas agregadas de condiciones clim치ticas (temperatura, presi칩n, viento, humedad, etc.) del centro, resumidas desde la base de datos `clima`. Se generan solo si la pregunta lo requiere.
    - **`centros_con_clima`**: Lista de centros (id, nombre, c칩digo) que tienen registros en la base `clima`.

Los centros pueden tener nombres distintos en cada base. Por ello, debes hacer *matching inteligente* entre nombres y coordenadas cuando sea necesario.

---

### 游빐 INSTRUCCIONES DIN츼MICAS (RAZONAMIENTO FLEXIBLE)

- **Responde Directamente**: Utiliza el contexto proporcionado para responder de manera clara y directa.
- **Detalle vs. Resumen**: Prioriza la informaci칩n detallada si `informes_ambientales_detallados` o `resumen_alimentacion_centro_actual` est치n disponibles. Si no, usa los res칰menes o datos b치sicos.
- **Gr치ficos y Comparaciones**:
    - Si el usuario solicita un gr치fico o una comparaci칩n ("gr치fico", "comparaci칩n", "tendencia", "evoluci칩n", "칰ltimos X informes"), busca los datos relevantes dentro de la **lista `informes_ambientales_detallados`**.
    - Si `informes_ambientales_detallados` contiene **m칰ltiples informes**, extrae las series de datos (ej. pH, redox) de cada informe, utilizando su `report_date` o `filename` para diferenciarlos en el gr치fico.
    - Si encuentras los datos adecuados, genera un bloque JSON para visualizaci칩n. Aseg칰rate de que los nombres de los campos en el JSON del gr치fico (`xAxis`, `series.name`, `series.data`) sean consistentes con lo que tu frontend espera. Para comparaciones, cada serie podr칤a representar un informe diferente o un valor a lo largo del tiempo/informes.

- **Gr치ficos y Comparaciones**:
    - Si el usuario solicita un gr치fico o una comparaci칩n ("gr치fico", "comparaci칩n", "visualizar", "evoluci칩n", "hazme un gr치fico", "crea un gr치fico"), y tienes los datos relevantes en el contexto `informes_ambientales_detallados` o `resumen_alimentacion_centro_actual`:
        - **Tu objetivo principal es generar un bloque JSON con el gr치fico solicitado.**
        - **Para gr치ficos generales de par치metros como pH o Redox (cuando no se especifica 'por estaci칩n'):**
            - **Usa los valores representativos o promedios del informe, no los datos detallados por estaci칩n.**
            - Si hay un solo informe, el `xAxis` puede ser la fecha del informe o un nombre descriptivo (ej. "Informe [Fecha]"). El `series.data` contendr치 ese 칰nico valor.
            - Si hay varios informes, usa las fechas de los informes como `xAxis`. La serie de datos (`series.data`) debe contener los valores correspondientes extra칤dos para cada informe.
        - Si el usuario pide expl칤citamente datos "por estaci칩n" o "por punto de muestreo" (ej. "gr치fico de pH por estaci칩n"), entonces usa esos datos para el gr치fico, con las estaciones como `xAxis`.
        - Siempre genera el JSON del gr치fico si los datos son adecuados para ello. Si no hay datos suficientes o el formato no es adecuado, informa al usuario.

Ejemplo de formato JSON para gr치fico (adaptado para m칰ltiples informes):
```json
{{
    "chart": {{
    "type": "line",
    "title": "Comparaci칩n de pH y Redox - Centro Pirquen",
    "xAxis": ["Informe Marzo 2023", "Informe Julio 2023"], // O las fechas o nombres de archivo para cada informe
    "series": [
     {{ "name": "pH (Informe Marzo)", "data": [7.3, 7.4] }}, // Ajusta las series para diferenciar por informe
     {{ "name": "Redox (Informe Julio)", "data": [170, 175] }}
    ]
 }}
}}
```

4. **CONTEXTO ESPEC칈FICO DISPONIBLE**:
```json
{context_str}
```


"""
        # Generar la respuesta de la IA
        response = client.chat.completions.create(
            model=settings.azure_openai_deployment,
            messages=[
                {"role": "system", "content": prompt_content},
                {"role": "user", "content": request.user_question}
            ],
            max_tokens=30000
        )

        ai_answer = response.choices[0].message.content

        # Intentar extraer bloque JSON de gr치fico si existe
        import re, json as pyjson
        chart_data = None
        chart_match = re.search(r'```json\s*({[\s\S]*?})\s*```', ai_answer)
        if chart_match:
            try:
                chart_json = chart_match.group(1)
                chart_obj = pyjson.loads(chart_json)
                if 'chart' in chart_obj:
                    chart_data = chart_obj['chart']
                # Eliminar el bloque JSON de la respuesta textual
                ai_answer = re.sub(r'```json[\s\S]*?```', '', ai_answer).strip()
            except Exception as e:
                logger.error(f"Error al parsear el bloque de gr치fico JSON: {e}")
                chart_data = None

        chat_entry = {
            "user_question": request.user_question,
            "ai_answer": ai_answer,
            "center_id": request.center_id,
            "informe_filename": request.informe_filename,
            "timestamp": datetime.utcnow(),
            "tokens_used": response.usage.total_tokens
        }
        chat_history_collection.insert_one(chat_entry)
        audio_base64 = None
        try:
            audio_response = tts_client.audio.speech.create(
                input=ai_answer,
                model=settings.azure_openai_tts_deployment,
                voice="onyx",
                response_format="mp3"
            )
            audio_bytes = audio_response.content
            audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
        except Exception as tts_e:
            logger.error(f"Error al sintetizar audio para la respuesta: {tts_e}")
            audio_base64 = None
        # Incluir chart si existe
        result = {"answer": ai_answer, "audio_base64": audio_base64}
        if chart_data:
            result["chart"] = chart_data
        return result
    except Exception as e:
        logger.error(f"Error al analizar la pregunta: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error al procesar la pregunta: {str(e)}") 